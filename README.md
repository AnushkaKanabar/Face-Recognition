This project's main objective is to propose a creative hypothetical method for helping the visually impaired. With the help of our model, we hope to mitigate some of the major issues that the visually impaired face today while also enhancing their sense of security and independence.
To begin with, we trained our algorithm using a sample dataset of characters from the film Jurassic Park. 
By feeding the algorithm with their photos and allowing it to identify and recognize their faces, we then attempted to put the system to the test. 
Additionally, we offered a real-time video input, which our system looped into a number of frames before processing each frame with a facial recognition algorithm. 
Once our system has identified the person, we convert the text to voice so that visually impaired people can hear the name of the person in front of them.
The proposed model uses Deep Metric Learning which is a combination of rules or a complex function that basically maps the inputs to the corresponding output labels.

Our project is broadly divided into three parts: 
1) Face detection: 
In this step, the task of the model is to determine whether a given group of images belong to a certain person or not 
2) Face recognition: 
This step involves both, face identification and detection. In the identification step, the task of the model is to recognize a person from a database of images 
3) Text to speech of the output of the recognized person
